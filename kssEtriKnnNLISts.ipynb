{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4be049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from kss import split_sentences\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import re\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2501ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hanspell import spell_checker\n",
    "from soynlp.normalizer import *\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19140b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETRI_API_KEY = \"6e228975-a883-40c6-b197-6945c71cb977\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec949a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 리스트\n",
    "stopwords = [\"이\", \"그\", \"저\", \"의\", \"을\", \"를\", \"은\", \"는\", \"에\", \"가\", \"와\", \"으로\", \"에서\",\"책\",\"추천\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8891aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/u4026/CBNU_KoSentenceBERT_SKT/.cache/kobert_v1.zip\n",
      "using cached model. /home/u4026/CBNU_KoSentenceBERT_SKT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /home/u4026/CBNU_KoSentenceBERT_SKT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "Load Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u4026/.local/lib/python3.8/site-packages/sentence_transformers/models/Transformer.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.auto_model.load_state_dict(torch.load(model_name_or_path+'/result.pt'))\n"
     ]
    }
   ],
   "source": [
    "model_path = '/home/u4026/KoSentenceBERT_SKTBERT/output/training_sts'\n",
    "model = SentenceTransformer(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18706d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/u4026/CBNU_KoSentenceBERT_SKT/.cache/kobert_v1.zip\n",
      "using cached model. /home/u4026/CBNU_KoSentenceBERT_SKT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /home/u4026/CBNU_KoSentenceBERT_SKT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "Load Model\n"
     ]
    }
   ],
   "source": [
    "nli_model_path = '/home/u4026/KoSentenceBERT_SKTBERT/output/training_nli'\n",
    "nli_model = SentenceTransformer(nli_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d512730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 로드\n",
    "csv_file = \"books_summary.csv\"\n",
    "data = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd2dab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리된 텍스트 열 추출\n",
    "corpus = data['내용요약'].tolist()\n",
    "titles = data['첵제목'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d2f7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms2(word):\n",
    "    url = \"http://aiopen.etri.re.kr:8000/WiseNLU\"\n",
    "    headers = {\n",
    "        \"Authorization\": ETRI_API_KEY,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\n",
    "        \"argument\": {\n",
    "            \"text\": word,\n",
    "            \"analysis_code\": \"morp\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        # API 응답 데이터 구조에 따라 유의어 추출\n",
    "        word_info = result.get(\"return_object\", {}).get(\"sentence\", [])\n",
    "        synonyms = []\n",
    "        for sentence in word_info:\n",
    "            for morp in sentence.get(\"morp\", []):\n",
    "                if morp.get(\"type\") == \"NNG\":  # 명사(NNG) 추출 예시\n",
    "                    synonyms.append(morp.get(\"lemma\"))\n",
    "        return synonyms\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68a1b326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_text(text):\n",
    "    # 1. 맞춤법 교정\n",
    "    text = spell_checker.check(text).checked\n",
    "\n",
    "\n",
    "    # 2. 특수문자 및 숫자 제거\n",
    "    text = re.sub(r\"[^가-힣0-9\\s]\", \"\", text)\n",
    "    \n",
    "    #반복되는 말 정규화\n",
    "    text = repeat_normalize(text, num_repeats=2)\n",
    "\n",
    "    # 3. 불용어 제거\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "\n",
    "    # 4. 유의어 교체\n",
    "    synonym_map = {}\n",
    "    for word in words:\n",
    "        synonyms = get_synonyms2(word)\n",
    "        if synonyms:\n",
    "            synonym_map[word] = synonyms[0]  # 첫 번째 유의어로 교체\n",
    "\n",
    "    replaced_words = [synonym_map.get(word, word) for word in words]\n",
    "    return \" \".join(replaced_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdac2846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내용요약을 문장별로 나누기\n",
    "def split_corpus(corpus):\n",
    "    split_sentences_corpus = []\n",
    "    mapping = []  # 원본 데이터의 인덱스 매핑\n",
    "    for idx, text in enumerate(corpus):\n",
    "        sentences = split_sentences(text)\n",
    "        split_sentences_corpus.extend(sentences)\n",
    "        mapping.extend([idx] * len(sentences))\n",
    "    return split_sentences_corpus, mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06d1be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 후보군 찾기 (KNN 활용)\n",
    "def find_candidates_with_knn(query, split_corpus, mapping, titles, n_neighbors=3):\n",
    "    # STS 임베딩 생성\n",
    "    corpus_embeddings = model.encode(split_corpus)\n",
    "    query_embedding = model.encode([query])\n",
    "\n",
    "    # Nearest Neighbors 모델 초기화 및 학습\n",
    "    knn = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine')\n",
    "    knn.fit(corpus_embeddings)\n",
    "\n",
    "    # Query와 가장 가까운 이웃 찾기\n",
    "    distances, indices = knn.kneighbors(query_embedding)\n",
    "\n",
    "    candidates = []\n",
    "    for dist, idx in zip(distances[0], indices[0]):\n",
    "        original_idx = mapping[idx]\n",
    "        candidates.append({\n",
    "            \"책제목\": titles[original_idx],\n",
    "            \"내용요약\": split_corpus[idx],\n",
    "            \"유사도\": 1 - dist  # 코사인 거리 -> 유사도로 변환\n",
    "        })\n",
    "\n",
    "    # 유사도를 기준으로 정렬\n",
    "    return sorted(candidates, key=lambda x: x[\"유사도\"], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c97dcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 유사도 평가 (STS 활용)\n",
    "def evaluate_with_sts(query, candidates):\n",
    "    query_embedding = model.encode([query], convert_to_tensor=True)\n",
    "    results = []\n",
    "\n",
    "    for candidate in candidates:\n",
    "        corpus_embedding = model.encode([candidate['내용요약']], convert_to_tensor=True)\n",
    "        similarity = util.pytorch_cos_sim(query_embedding, corpus_embedding).item()\n",
    "\n",
    "        results.append({\n",
    "            \"책제목\": candidate['책제목'],\n",
    "            \"내용요약\": candidate['내용요약'],\n",
    "            \"유사도\": similarity\n",
    "        })\n",
    "\n",
    "    # 유사도를 기준으로 정렬\n",
    "    return sorted(results, key=lambda x: x[\"유사도\"], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c2be338",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_corpus = [preprocess_text(text) for text in corpus[:50]]\n",
    "#test_corpus = \"새 교육과정에 따른 평가기준의 개발이 필요해서, 한국교육과정평가원에서는 총론과 교과별 평가기준 등을 연구 개발 하였다.  핵심 개발 방향은 2015년 개정 교육과정이 학교현장에서 운영되도록 하는 것이다.한국과 독일 금형산업의 노동시장과 숙련형성 비교연구,,특성화고 전체 취업률은 약 45%, 마이스터고는 약 82%, 폴리텍은 약 86%, 2년제 전문대는 약 65%로 금형과 졸업자의 취업률은 학교별로 차이가 있다.\"\n",
    "#pre_corpus= preprocess_text(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bacb7cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새 교육 따른 평가 기준 개발 필요 교육 총론 교과 평가 기준 등 연구 개발 핵심 개발 방향 2015년 개정 교육 학교 현장 운영 하는 것이다 한국과 독일 금형 노동 숙련 형성 비교 연구 특성 전체 취업 약 45 마이스터고는 약 82 폴리텍은 약 86 2년제 전문 약 65로 금형 졸업 취업 학교 차이 있다\n"
     ]
    }
   ],
   "source": [
    "print(pre_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4594ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트를 입력하세요: 새 교육과정에 따른 평가내용이 담긴 책추천해줘\n"
     ]
    }
   ],
   "source": [
    "# 사용자가 입력한 텍스트\n",
    "query = input(\"텍스트를 입력하세요: \")\n",
    "pre_query=preprocess_text(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11529133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새 교육 따른 평가 내용 담긴 추천 줘\n"
     ]
    }
   ],
   "source": [
    "print(pre_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33f0ed0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Kss]: Oh! You have mecab in your environment. Kss will take this as a backend! :D\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'책제목': '교육광장 2016 겨울호 (Vol. 62)', '내용요약': '새 교육 따른 평가 기준 개발 필요 교육 총론 교과 평가 기준 등 연구 개발 핵심 개발 방향 2015년 개정 교육 학교 현장 운영 하는 것이다', '유사도': 0.5710244178771973}, {'책제목': '미래 사회 교육 환경 변화에 따른 교과서 발전 방안 세미나', '내용요약': '교과 개발 대한 의견 교과 개발 주체 현재 다양 지식 형성 집단 지성 활용 현재 같은 방식 학생 교과 개발 참여 순 나타났다', '유사도': 0.48304980993270874}, {'책제목': '국민 삶의 질 측정 2016', '내용요약': '일부 국가 지표 작성 과정 하향 상향 보완 방식 사용 중 이러한 방식 통해 전문 중심 아닌 국민 참여 기반 국민 체감 높은 지표 작성 가능', '유사도': 0.39754611253738403}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 1: 내용요약을 문장별로 나누기\n",
    "split_corpus_data, mapping = split_corpus(pre_corpus)\n",
    "\n",
    "# Step 2: KNN으로 후보군 찾기\n",
    "candidates = find_candidates_with_knn(pre_query, split_corpus_data, mapping, titles, n_neighbors=3)\n",
    "\n",
    "# Step 3: STS로 최종 유사도 계산\n",
    "final_results = evaluate_with_sts(query, candidates)\n",
    "\n",
    "print(final_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
