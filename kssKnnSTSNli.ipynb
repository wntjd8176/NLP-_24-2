{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4be049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from kss import split_sentences\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aad8ea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8891aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/u4026/CBNU_KoSentenceBERT_SKT/.cache/kobert_v1.zip\n",
      "using cached model. /home/u4026/CBNU_KoSentenceBERT_SKT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /home/u4026/CBNU_KoSentenceBERT_SKT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "Load Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u4026/.local/lib/python3.8/site-packages/sentence_transformers/models/Transformer.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.auto_model.load_state_dict(torch.load(model_name_or_path+'/result.pt'))\n"
     ]
    }
   ],
   "source": [
    "model_path = '/home/u4026/KoSentenceBERT_SKTBERT/output/training_sts'\n",
    "model = SentenceTransformer(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18706d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/u4026/CBNU_KoSentenceBERT_SKT/.cache/kobert_v1.zip\n",
      "using cached model. /home/u4026/CBNU_KoSentenceBERT_SKT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /home/u4026/CBNU_KoSentenceBERT_SKT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "Load Model\n"
     ]
    }
   ],
   "source": [
    "nli_model_path = '/home/u4026/KoSentenceBERT_SKTBERT/output/training_nli'\n",
    "nli_model = SentenceTransformer(nli_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d512730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 로드\n",
    "csv_file = \"books_summary.csv\"\n",
    "data = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd2dab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리된 텍스트 열 추출\n",
    "corpus = data['내용요약'].tolist()\n",
    "titles = data['첵제목'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdac2846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내용요약을 문장별로 나누기\n",
    "def split_corpus(corpus):\n",
    "    split_sentences_corpus = []\n",
    "    mapping = []  # 원본 데이터의 인덱스 매핑\n",
    "    for idx, text in enumerate(corpus):\n",
    "        sentences = split_sentences(text)\n",
    "        split_sentences_corpus.extend(sentences)\n",
    "        mapping.extend([idx] * len(sentences))\n",
    "    return split_sentences_corpus, mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01a73f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 임베딩 계산\n",
    "def calculate_average_embedding(sentences, model):\n",
    "    embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "    return embeddings.mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3bdf6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#후보군 찾기 (STS 활용, 평균 임베딩)\n",
    "def find_candidates_with_sts_average(query, split_corpus, mapping, titles, n_neighbors=3):\n",
    "    average_embeddings = []\n",
    "    unique_indices = list(set(mapping))\n",
    "\n",
    "    for idx in unique_indices:\n",
    "        sentences = [split_corpus[i] for i in range(len(mapping)) if mapping[i] == idx]\n",
    "        avg_embedding = calculate_average_embedding(sentences, model)\n",
    "        average_embeddings.append(avg_embedding)\n",
    "\n",
    "    average_embeddings = torch.stack(average_embeddings)\n",
    "    query_embedding = calculate_average_embedding([query], model)\n",
    "\n",
    "    # 코사인 유사도 계산\n",
    "    similarities = util.pytorch_cos_sim(query_embedding, average_embeddings)\n",
    "    top_indices = torch.topk(similarities[0], k=n_neighbors, largest=True).indices.tolist()\n",
    "\n",
    "    candidates = []\n",
    "    for idx in top_indices:\n",
    "         if isinstance(idx, int):\n",
    "            original_idx = unique_indices[idx]\n",
    "            candidates.append({\n",
    "              \"책제목\": titles[original_idx],\n",
    "              \"내용요약\": corpus[original_idx],\n",
    "               \"유사도\": similarities[0][idx].item()\n",
    "        })\n",
    "    return sorted(candidates, key=lambda x: x[\"유사도\"], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06d1be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 후보군 찾기 (KNN 활용)\n",
    "def find_candidates_with_knn(query, split_corpus, mapping, titles, n_neighbors=3):\n",
    "    # STS 임베딩 생성\n",
    "    corpus_embeddings = model.encode(split_corpus)\n",
    "    query_embedding = model.encode([query])\n",
    "\n",
    "    # Nearest Neighbors 모델 초기화 및 학습\n",
    "    knn = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine')\n",
    "    knn.fit(corpus_embeddings)\n",
    "\n",
    "    # Query와 가장 가까운 이웃 찾기\n",
    "    distances, indices = knn.kneighbors(query_embedding)\n",
    "\n",
    "    candidates = []\n",
    "    for dist, idx in zip(distances[0], indices[0]):\n",
    "        original_idx = mapping[idx]\n",
    "        candidates.append({\n",
    "            \"책제목\": titles[original_idx],\n",
    "            \"내용요약\": split_corpus[idx],\n",
    "            \"유사도\": 1 - dist  # 코사인 거리 -> 유사도로 변환\n",
    "        })\n",
    "\n",
    "    # 유사도를 기준으로 정렬\n",
    "    return sorted(candidates, key=lambda x: x[\"유사도\"], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c97dcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 유사도 평가 (STS 활용)\n",
    "def evaluate_with_sts(query, candidates):\n",
    "    query_embedding = model.encode([query], convert_to_tensor=True)\n",
    "    results = []\n",
    "\n",
    "    for candidate in candidates:\n",
    "        corpus_embedding = model.encode([candidate['내용요약']], convert_to_tensor=True)\n",
    "        similarity = util.pytorch_cos_sim(query_embedding, corpus_embedding).item()\n",
    "\n",
    "        results.append({\n",
    "            \"책제목\": candidate['책제목'],\n",
    "            \"내용요약\": candidate['내용요약'],\n",
    "            \"유사도\": similarity\n",
    "        })\n",
    "\n",
    "    # 유사도를 기준으로 정렬\n",
    "    return sorted(results, key=lambda x: x[\"유사도\"], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a856de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 최종 유사도 평가 (NLI 활용)\n",
    "def evaluate_with_nli(query, candidates):\n",
    "    query_embedding = nli_model.encode([query], convert_to_tensor=True)\n",
    "    results = []\n",
    "\n",
    "    for candidate in candidates:\n",
    "        corpus_embedding = nli_model.encode([candidate['내용요약']], convert_to_tensor=True)\n",
    "        #top_indices = torch.topk(similarities[0], k=n_neighbors, largest=True).indices.tolist()\n",
    "        similarity = util.pytorch_cos_sim(query_embedding, corpus_embedding).item()\n",
    "\n",
    "        results.append({\n",
    "            \"책제목\": candidate['책제목'],\n",
    "            \"내용요약\": candidate['내용요약'],\n",
    "            \"유사도\": similarity\n",
    "        })\n",
    "    return sorted(results, key=lambda x: x[\"유사도\"], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4594ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트를 입력하세요: 새 교육과정에 따른 평가기준에 관한 내용의 책 추천해줘\n"
     ]
    }
   ],
   "source": [
    "# 사용자가 입력한 텍스트\n",
    "query = input(\"텍스트를 입력하세요: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33f0ed0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'책제목': '교육광장 2016 겨울호 (Vol. 62)', '내용요약': '새 교육과정에 따른 평가기준의 개발이 필요해서, 한국교육과정평가원에서는 총론과 교과별 평가기준 등을 연구 개발 하였다.  핵심 개발 방향은 2015년 개정 교육과정이 학교현장에서 운영되도록 하는 것이다.', '유사도': 0.9067184925079346}, {'책제목': '2013년 국가수준 학업성취도 평가 결과: 인지적·정의적 특성 및 변화 추이', '내용요약': '우리나라 학생들이 의사결정 영향력을 가장 체감하는 영역은 소풍과 수학여행 장소 결정 등으로 매우 제한적인 반면, 다른 나라들의 경우 학생들이 교육과정 운영, 교사 채용 과정, 학교 규정 등에 영향력을 행사한다. 교육과정은 학교의 핵심 활동인 만큼 교원능력개발평가 등을 통해 교육과정 선정 과정에서 학생 참여를 증대할 필요가 있다. 이를 위해서는 현재의 교원능력개발평가문항을 보완하여 학생들이 수업에 대한 의견을 제시할 수 있도록 해야 한다.', '유사도': 0.8830466866493225}, {'책제목': '교육정책포럼 2015년 07월 (통권 265호)', '내용요약': '개정 교육과정의 운영 방법을 명확히 하기 위해 전반적으로 학생들의 학습 강점과 요구사항 등을 교육과정에 적절히 반영하였다.', '유사도': 0.8808505535125732}]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: 내용요약을 문장별로 나누기\n",
    "split_corpus_data, mapping = split_corpus(corpus)\n",
    "\n",
    "# Step 2: STS으로 후보군 찾기\n",
    "candidates = find_candidates_with_sts_average(query, split_corpus_data, mapping, titles, n_neighbors=3)\n",
    "\n",
    "# Step 3: nli로 최종 유사도 계산\n",
    "final_results = evaluate_with_nli(query, candidates)\n",
    "\n",
    "print(final_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c291e926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "책제목: 교육광장 2016 겨울호 (Vol. 62)\n",
      "내용요약: 새 교육과정에 따른 평가기준의 개발이 필요해서, 한국교육과정평가원에서는 총론과 교과별 평가기준 등을 연구 개발 하였다.  핵심 개발 방향은 2015년 개정 교육과정이 학교현장에서 운영되도록 하는 것이다.\n",
      "유사도: 0.9067184925079346\n",
      "\n",
      "책제목: 2013년 국가수준 학업성취도 평가 결과: 인지적·정의적 특성 및 변화 추이\n",
      "내용요약: 우리나라 학생들이 의사결정 영향력을 가장 체감하는 영역은 소풍과 수학여행 장소 결정 등으로 매우 제한적인 반면, 다른 나라들의 경우 학생들이 교육과정 운영, 교사 채용 과정, 학교 규정 등에 영향력을 행사한다. 교육과정은 학교의 핵심 활동인 만큼 교원능력개발평가 등을 통해 교육과정 선정 과정에서 학생 참여를 증대할 필요가 있다. 이를 위해서는 현재의 교원능력개발평가문항을 보완하여 학생들이 수업에 대한 의견을 제시할 수 있도록 해야 한다.\n",
      "유사도: 0.8830466866493225\n",
      "\n",
      "책제목: 교육정책포럼 2015년 07월 (통권 265호)\n",
      "내용요약: 개정 교육과정의 운영 방법을 명확히 하기 위해 전반적으로 학생들의 학습 강점과 요구사항 등을 교육과정에 적절히 반영하였다.\n",
      "유사도: 0.8808505535125732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for result in final_results:\n",
    "    print(f\"책제목: {result['책제목']}\\n내용요약: {result['내용요약']}\\n유사도: {result['유사도']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
