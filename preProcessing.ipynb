{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54b30377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import language_tool_python\n",
    "from hanspell import spell_checker\n",
    "from soynlp.normalizer import *\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "80e630ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting soynlp\n",
      "  Downloading soynlp-0.0.493-py3-none-any.whl (416 kB)\n",
      "\u001b[K     |████████████████████████████████| 416 kB 9.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.8/dist-packages (from soynlp) (5.9.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/u4026/.local/lib/python3.8/site-packages (from soynlp) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.8/dist-packages (from soynlp) (1.23.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from soynlp) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/u4026/.local/lib/python3.8/site-packages (from scikit-learn>=0.20.0->soynlp) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->soynlp) (1.2.0)\n",
      "Installing collected packages: soynlp\n",
      "Successfully installed soynlp-0.0.493\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install soynlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae5a1bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETRI_API_KEY = \"c7d165fa-4ecf-4047-967d-b593a628c568\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acfb715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 리스트\n",
    "stopwords = [\"이\", \"그\", \"저\", \"의\", \"을\", \"를\", \"은\", \"는\", \"에\", \"가\", \"와\", \"으로\", \"에서\",\"추천\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c878b6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ETRI API를 사용하여 맞춤법 교정하기\n",
    "def correct_text_etri(text):\n",
    "    url = \"http://aiopen.etri.re.kr:8000/WiseNLU\"\n",
    "    headers = {\n",
    "        \"Authorization\": ETRI_API_KEY,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\n",
    "        \"argument\": {\n",
    "            \"text\": text,\n",
    "            \"analysis_code\": \"morp\"  # 형태소 분석 코드, 맞춤법 및 문법 교정 포함\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        if \"return_object\" in result and \"sentence\" in result[\"return_object\"]:\n",
    "            sentences = result[\"return_object\"][\"sentence\"]\n",
    "            corrected_text = \" \".join([sent[\"text\"] for sent in sentences])\n",
    "            return corrected_text\n",
    "        else:\n",
    "            return \"결과가 없습니다.\"\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59911388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_text_etri2(text):\n",
    "    url = \"http://aiopen.etri.re.kr:8000/WiseNLU\"\n",
    "    headers = {\n",
    "        \"Authorization\": ETRI_API_KEY,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\n",
    "        \"argument\": {\n",
    "            \"text\": text,\n",
    "            \"analysis_code\": \"morp\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        words = []\n",
    "        for sentence in result[\"return_object\"][\"sentence\"]:\n",
    "            for morp in sentence[\"morp\"]:\n",
    "                words.append(morp[\"lemma\"])\n",
    "        return \" \".join(words)\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f12105ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETRI API를 사용하여 유의어 가져오기\n",
    "def get_synonyms(word):\n",
    "    url = \"http://aiopen.etri.re.kr:8000/WiseWWN/Word\"\n",
    "    headers = {\"Authorization\": ETRI_API_KEY, \"Content-Type\": \"application/json\"}\n",
    "    data = {\"request_id\": \"reserved field\", \"argument\": {\"word\": word}}\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        return result.get(\"return_object\", {}).get(\"WWN WordInfo\", {}).get(\"synonym\", [])\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "191e4c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['활동']\n"
     ]
    }
   ],
   "source": [
    "def get_synonyms_from_etri(word):\n",
    "    url = \"http://aiopen.etri.re.kr:8000/WiseNLU\"\n",
    "    headers = {\"Authorization\": ETRI_API_KEY, \"Content-Type\": \"application/json\"}\n",
    "    data = {\n",
    "        \"argument\": {\n",
    "            \"text\": word,\n",
    "            \"analysis_code\": \"morp\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        return [morp['lemma'] for sentence in result['return_object']['sentence']\n",
    "                for morp in sentence['morp'] if morp['type'] == 'NNG']  # 명사만 추출\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "print(get_synonyms_from_etri(\"활동\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cca83b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms2(word):\n",
    "    url = \"http://aiopen.etri.re.kr:8000/WiseNLU\"\n",
    "    headers = {\n",
    "        \"Authorization\": ETRI_API_KEY,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\n",
    "        \"argument\": {\n",
    "            \"text\": word,\n",
    "            \"analysis_code\": \"morp\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        # API 응답 데이터 구조에 따라 유의어 추출\n",
    "        word_info = result.get(\"return_object\", {}).get(\"sentence\", [])\n",
    "        synonyms = []\n",
    "        for sentence in word_info:\n",
    "            for morp in sentence.get(\"morp\", []):\n",
    "                if morp.get(\"type\") == \"NNG\":  # 명사(NNG) 추출 예시\n",
    "                    synonyms.append(morp.get(\"lemma\"))\n",
    "        return synonyms\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ff6b78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_text(text):\n",
    "    # 1. 맞춤법 교정\n",
    "    text = spell_checker.check(text).checked\n",
    "\n",
    "\n",
    "    # 2. 특수문자 및 숫자 제거\n",
    "    text = re.sub(r\"[^가-힣0-9\\s]\", \"\", text)\n",
    "    \n",
    "    #반복되는 말 정규화\n",
    "    text = repeat_normalize(text, num_repeats=2)\n",
    "\n",
    "    # 3. 불용어 제거\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "\n",
    "    # 4. 유의어 교체\n",
    "    synonym_map = {}\n",
    "    for word in words:\n",
    "        synonyms = get_synonyms2(word)\n",
    "        if synonyms:\n",
    "            synonym_map[word] = synonyms[0]  # 첫 번째 유의어로 교체\n",
    "\n",
    "    replaced_words = [synonym_map.get(word, word) for word in words]\n",
    "    return \" \".join(replaced_words)\n",
    "\n",
    " # 유의어 교체 없이 반환\n",
    "   # return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9841f9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': True,\n",
       " 'original': '안녕 하세요. 저는 한국인 입니다. 이문장은 한글로 작성됬습니다.',\n",
       " 'checked': '안녕하세요. 저는 한국인입니다. 이 문장은 한글로 작성됐습니다.',\n",
       " 'errors': 4,\n",
       " 'words': OrderedDict([('안녕하세요.', 2),\n",
       "              ('저는', 0),\n",
       "              ('한국인입니다.', 2),\n",
       "              ('이', 2),\n",
       "              ('문장은', 2),\n",
       "              ('한글로', 0),\n",
       "              ('작성됐습니다.', 1)]),\n",
       " 'time': 0.1473238468170166}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = spell_checker.check('안녕 하세요. 저는 한국인 입니다. 이문장은 한글로 작성됬습니다.')\n",
    "result.as_dict()  # dict로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf93269d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일 생성 완료: books.csv\n"
     ]
    }
   ],
   "source": [
    "# 데이터 입력\n",
    "book_data = [\n",
    "    {\"제목\": \"소년이 온다\",\"작가\": \"한강\", \"내용\": \" 소설은 6개의 장으로 나누어져 있었는데요 각 장마다 다른 인물의 시선으로 이야기가 진행되고 있었어요 주인공들은 광주에서 일어난 시위 사건 속에 있던 사람들로 각자의 슬픔을 안고 살아가고 있습니다.\"},\n",
    "    {\"제목\": \"책 제목 2\", \"작가\": \"작가 이름 2\", \"내용\": \"다른 주제를 다룬 책입니다.\"},\n",
    "    {\"제목\": \"책 제목 3\", \"작가\": \"작가 이름 3\", \"내용\": \"흥미로운 이야기가 담긴 책입니다.\"}\n",
    "]\n",
    "\n",
    "# DataFrame 생성\n",
    "df = pd.DataFrame(book_data)\n",
    "\n",
    "# CSV 파일로 저장\n",
    "csv_file = \"books.csv\"\n",
    "df.to_csv(csv_file, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"CSV 파일 생성 완료: {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73de8d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       제목       작가                                                 내용  \\\n",
      "0  소년이 온다       한강   소설은 6개의 장으로 나누어져 있었는데요 각 장마다 다른 인물의 시선으로 이야기가...   \n",
      "1  책 제목 2  작가 이름 2                                    다른 주제를 다룬 책입니다.   \n",
      "2  책 제목 3  작가 이름 3                                 흥미로운 이야기가 담긴 책입니다.   \n",
      "\n",
      "                                             전처리된 내용  \n",
      "0  소설은 6개의 장으로 나누어져 있었는데요 각 장마다 다른 인물의 시선으로 이야기가 ...  \n",
      "1                                     다른 주제를 다룬 책입니다  \n",
      "2                                  흥미로운 이야기가 담긴 책입니다  \n",
      "전처리된 CSV 파일 저장 완료: processed_books.csv\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"books.csv\"\n",
    "df = pd.read_csv(csv_file, encoding=\"utf-8-sig\")\n",
    "\n",
    "# 내용에 전처리 함수 적용\n",
    "df[\"전처리된 내용\"] = df[\"내용\"].apply(preprocess_text)\n",
    "\n",
    "# 결과 확인\n",
    "print(df)\n",
    "\n",
    "# 전처리된 데이터를 새로운 CSV 파일로 저장\n",
    "processed_csv_file = \"processed_books.csv\"\n",
    "df.to_csv(processed_csv_file, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"전처리된 CSV 파일 저장 완료: {processed_csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93fd0d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 결과: 민주 운동 과정 희생 시민 이야기 쓴 소설 추천\n"
     ]
    }
   ],
   "source": [
    "# 예제 입력 텍스트\n",
    "user_text = \"민주화 운동과정에서 희생된 시민들의 이야기를 쓴 소설을 추천해줘ㅋㅋㅋㅋㅋㅋㅋ ㅎㅎ\"\n",
    "\n",
    "# 전처리 수행\n",
    "preprocessed_text = preprocess_text(user_text)\n",
    "\n",
    "print(f\"전처리 결과: {preprocessed_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
