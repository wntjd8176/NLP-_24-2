{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "732df096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b546133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hanspell import spell_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66371cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from soynlp.normalizer import *\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "317fba79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7335bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kss\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffeb35c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "817d7630",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETRI_API_KEY = \"c7d165fa-4ecf-4047-967d-b593a628c568\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6a43863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/u4026/CBNU_KoSentenceBERT_SKT/.cache/kobert_v1.zip\n",
      "using cached model. /home/u4026/CBNU_KoSentenceBERT_SKT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /home/u4026/CBNU_KoSentenceBERT_SKT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "Load Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u4026/.local/lib/python3.8/site-packages/sentence_transformers/models/Transformer.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.auto_model.load_state_dict(torch.load(model_name_or_path+'/result.pt'))\n"
     ]
    }
   ],
   "source": [
    "model_path = '/home/u4026/KoSentenceBERT_SKTBERT/output/training_sts'\n",
    "model = SentenceTransformer(model_path)\n",
    "#model = SentenceTransformer(\"distiluse-base-multilingual-cased-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58813c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/u4026/CBNU_KoSentenceBERT_SKT/.cache/kobert_v1.zip\n",
      "using cached model. /home/u4026/CBNU_KoSentenceBERT_SKT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /home/u4026/CBNU_KoSentenceBERT_SKT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "Load Model\n"
     ]
    }
   ],
   "source": [
    "nli_model_path = '/home/u4026/KoSentenceBERT_SKTBERT/output/training_nli'\n",
    "nli_model = SentenceTransformer(nli_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0d699b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 리스트\n",
    "stopwords = [\"이\", \"그\", \"저\", \"의\", \"을\", \"를\", \"은\", \"는\", \"에\", \"가\", \"와\", \"으로\", \"에서\",\"추천\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a513f58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사도 점수: 0.7578798532485962\n"
     ]
    }
   ],
   "source": [
    "premise = \"새 교육과정에 따른 평가내용이 담긴 책추천해줘\"\n",
    "hypothesis = \"새 교육과정에 따른 평가기준의 개발이 필요해서, 한국교육과정평가원에서는 총론과 교과별 평가기준 등을 연구 개발 하였다.  핵심 개발 방향은 2015년 개정 교육과정이 학교현장에서 운영되도록 하는 것이다.한국과 독일 금형산업의 노동시장과 숙련형성 비교연구,,특성화고 전체 취업률은 약 45%, 마이스터고는 약 82%, 폴리텍은 약 86%, 2년제 전문대는 약 65%로 금형과 졸업자의 취업률은 학교별로 차이가 있다.\"\n",
    "\n",
    "embeddings = nli_model.encode([premise, hypothesis], convert_to_tensor=True)\n",
    "cosine_score = util.pytorch_cos_sim(embeddings[0], embeddings[1])\n",
    "\n",
    "print(f\"유사도 점수: {cosine_score.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5901a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.46.3\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: /home/u4026/.local/lib/python3.8/site-packages\n",
      "Requires: regex, filelock, pyyaml, tokenizers, huggingface-hub, safetensors, requests, numpy, tqdm, packaging\n",
      "Required-by: sentence-transformers, kobert\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d41cb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 로드\n",
    "csv_file = \"books_summary.csv\"\n",
    "data = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48a23ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms2(word):\n",
    "    url = \"http://aiopen.etri.re.kr:8000/WiseNLU\"\n",
    "    headers = {\n",
    "        \"Authorization\": ETRI_API_KEY,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\n",
    "        \"argument\": {\n",
    "            \"text\": word,\n",
    "            \"analysis_code\": \"morp\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        # API 응답 데이터 구조에 따라 유의어 추출\n",
    "        word_info = result.get(\"return_object\", {}).get(\"sentence\", [])\n",
    "        synonyms = []\n",
    "        for sentence in word_info:\n",
    "            for morp in sentence.get(\"morp\", []):\n",
    "                if morp.get(\"type\") == \"NNG\":  # 명사(NNG) 추출 예시\n",
    "                    synonyms.append(morp.get(\"lemma\"))\n",
    "        return synonyms\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e2bf7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_text(text):\n",
    "    # 1. 맞춤법 교정\n",
    "    text = spell_checker.check(text).checked\n",
    "\n",
    "\n",
    "    # 2. 특수문자 및 숫자 제거\n",
    "    text = re.sub(r\"[^가-힣0-9\\s]\", \"\", text)\n",
    "    \n",
    "    #반복되는 말 정규화\n",
    "    text = repeat_normalize(text, num_repeats=2)\n",
    "\n",
    "    # 3. 불용어 제거\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "\n",
    "    # 4. 유의어 교체\n",
    "    synonym_map = {}\n",
    "    for word in words:\n",
    "        synonyms = get_synonyms2(word)\n",
    "        if synonyms:\n",
    "            synonym_map[word] = synonyms[0]  # 첫 번째 유의어로 교체\n",
    "\n",
    "    replaced_words = [synonym_map.get(word, word) for word in words]\n",
    "    return \" \".join(replaced_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a532ff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_filter_sentences(text):\n",
    "    \"\"\"\n",
    "    텍스트를 KSS와 추가 기준으로 분리하고, 의미 없는 연결어를 제거\n",
    "    \"\"\"\n",
    "    # KSS로 1차 분리\n",
    "    sentences = kss.split_sentences(text)\n",
    "    \n",
    "    # 추가 기준 적용 ('그리고', '또', ',' 기준으로 분리)\n",
    "    split_sentences = []\n",
    "    for sentence in sentences:\n",
    "        parts = re.split(r'(그리고|또|,)', sentence)\n",
    "        parts = [p.strip() for p in parts if p.strip()]  # 공백 제거 및 빈 문자열 제거\n",
    "        split_sentences.extend(parts)\n",
    "    \n",
    "    # 불필요한 연결어 필터링\n",
    "    filtered_sentences = [s for s in split_sentences if s not in [\"그리고\", \"또\", \",\"]]\n",
    "    \n",
    "    return filtered_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7937482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_embedding(sentences, model):\n",
    "    \"\"\"\n",
    "    여러 문장의 임베딩 값을 평균화\n",
    "    \"\"\"\n",
    "    if not sentences:\n",
    "        return None  # 빈 입력에 대한 처리\n",
    "\n",
    "    embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "    avg_embedding = embeddings.mean(dim=0)  # 평균 계산\n",
    "    return avg_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffbcc847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리된 텍스트 열 추출\n",
    "corpus = data['내용요약'].tolist()\n",
    "titles = data['첵제목'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b086534f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Oh! You have mecab in your environment. Kss will take this as a backend! :D\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 코퍼스 문장 분리 및 임베딩 평균 계산\n",
    "corpus_embeddings = []\n",
    "for doc in corpus:\n",
    "    sentences = split_and_filter_sentences(doc)\n",
    "    avg_embedding = get_average_embedding(sentences, model)\n",
    "    corpus_embeddings.append(avg_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1bf265a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 의미있는 단어 남기는 전처리+코퍼스 임베딩 생성 \n",
    "test_corpus = \"새 교육과정에 따른 평가기준의 개발이 필요해서, 한국교육과정평가원에서는 총론과 교과별 평가기준 등을 연구 개발 하였다.  핵심 개발 방향은 2015년 개정 교육과정이 학교현장에서 운영되도록 하는 것이다.한국과 독일 금형산업의 노동시장과 숙련형성 비교연구,,특성화고 전체 취업률은 약 45%, 마이스터고는 약 82%, 폴리텍은 약 86%, 2년제 전문대는 약 65%로 금형과 졸업자의 취업률은 학교별로 차이가 있다.\"\n",
    "pre_corpus= preprocess_text(test_corpus)\n",
    "corpus_embeddings = model.encode(pre_corpus, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc97d427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새 교육 따른 평가 기준 개발 필요 교육 총론 교과 평가 기준 등 연구 개발 핵심 개발 방향 2015년 개정 교육 학교 현장 운영 하는 것이다 한국과 독일 금형 노동 숙련 형성 비교 연구 특성 전체 취업 약 45 마이스터고는 약 82 폴리텍은 약 86 2년제 전문 약 65로 금형 졸업 취업 학교 차이 있다\n"
     ]
    }
   ],
   "source": [
    "print(pre_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a5a1e52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트를 입력하세요: 새 교육과정에 따른 평가내용이 담긴 책추천해줘\n"
     ]
    }
   ],
   "source": [
    "# 사용자가 입력한 텍스트\n",
    "query = input(\"텍스트를 입력하세요: \")\n",
    "#query_sentences = split_and_filter_sentences(query)\n",
    "#query_embedding = get_average_embedding(query_sentences, model)\n",
    "\n",
    "#의미있는 단어 남기는 전처리+쿼리 임베딩 생성\n",
    "pre_query=preprocess_text(query)\n",
    "query_embedding = model.encode([pre_query], convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3e033877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새 교육 따른 평가 내용 담긴 책 추천 줘\n"
     ]
    }
   ],
   "source": [
    "print(pre_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c259174e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20e137bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: 요즘 우리나라 대통령이 개엄령을 일으켜서 놀라웠는데 예전에 있었던 광주시위에 관한책을 소개시켜줘 광주시위후 슬픔을 받는 사람들의 이야기였으면 해\n",
      "\n",
      "Top 3 most similar sentences in corpus:\n",
      "소설은 6개의 장으로 나누어져 있었는데요 각 장마다 다른 인물의 시선으로 이야기가 진행되고 있었어요 주인공들은 광주에서 일어난 시위 사건 속에 있던 사람들로 각자의 슬픔을 안고 살아가고 있습니다 (Score: 0.4742)\n",
      "소설은 6개의 장으로 나누어져 있었는데요 각 장마다 다른 인물의 시선으로 이야기가 진행되고 있었어요 주인공들은 광주에서 일어난 시위 사건 속에 있던 사람들로 각자의 슬픔을 안고 살아가고 있습니다 (Score: 0.2166)\n",
      "소설은 6개의 장으로 나누어져 있었는데요 각 장마다 다른 인물의 시선으로 이야기가 진행되고 있었어요 주인공들은 광주에서 일어난 시위 사건 속에 있던 사람들로 각자의 슬픔을 안고 살아가고 있습니다 (Score: 0.1448)\n"
     ]
    }
   ],
   "source": [
    "# 코사인 유사도 비교\n",
    "if query_embedding is not None:\n",
    "    cos_scores = [util.pytorch_cos_sim(query_embedding, corpus_embedding)[0].item() for corpus_embedding in corpus_embeddings]\n",
    "\n",
    "    # 상위 유사도 결과 출력\n",
    "    top_k = min(5, len(cos_scores))\n",
    "    top_results = np.argsort(cos_scores)[-top_k:][::-1]  # 유사도 높은 순으로 정렬\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop {} most similar sentences in corpus:\".format(top_k))\n",
    "\n",
    "    for idx in top_results:\n",
    "        print(f\"{corpus[0]} (Score: {cos_scores[idx]:.4f})\")\n",
    "else:\n",
    "    print(\"입력 텍스트에서 유효한 문장이 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8829e794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: 새 교육과정에 따른 평가내용이 담긴 책추천해줘\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "Title: 교육광장 2016 겨울호 (Vol. 62), Sentence: 새 교육과정에 따른 평가기준의 개발이 필요해서, 한국교육과정평가원에서는 총론과 교과별 평가기준 등을 연구 개발 하였다.  핵심 개발 방향은 2015년 개정 교육과정이 학교현장에서 운영되도록 하는 것이다. (Score: 0.2589)\n"
     ]
    }
   ],
   "source": [
    "# 코사인 유사도 계산\n",
    "cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "cos_scores = cos_scores.cpu()\n",
    "\n",
    "# 책 제목별 최고 유사도 선택\n",
    "best_results = {}\n",
    "for idx, score in enumerate(cos_scores):\n",
    "    title = titles[idx]\n",
    "    sentence = corpus[idx].strip()\n",
    "    if title not in best_results or best_results[title]['score'] < score.item():\n",
    "        best_results[title] = {'sentence': sentence, 'score': score.item()}\n",
    "\n",
    "    # 유사도 점수가 높은 순으로 정렬\n",
    "sorted_results = sorted(best_results.items(), key=lambda x: x[1]['score'], reverse=True)\n",
    "\n",
    "# 가장 유사한 결과 가져오기\n",
    "#top_k = 3\n",
    "#top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
    "top_k =1\n",
    "# 결과 출력\n",
    "print(\"\\n\\n======================\\n\\n\")\n",
    "print(\"Query:\", query)\n",
    "print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "for title, result in sorted_results[:top_k]:\n",
    "        print(f\"Title: {title}, Sentence: {result['sentence']} (Score: {result['score']:.4f})\")\n",
    "\n",
    "#for idx in top_results[0:top_k]:\n",
    "    #print(f\"Title: {titles[idx]}, Sentence: {corpus[idx].strip()} (Score: {cos_scores[idx]:.4f})\")\n",
    "    #print(f\"{corpus[idx].strip()} (Score: {cos_scores[idx]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "336a3aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: ['피고인은 엉덩이를 손으로 움켜쥐어 피해자를 강제로 추행하였다.']\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "피고인의 옆에서 수영 강습을 받기 위해 물에 엎드린 자세로 떠 있던 피해자의 엉덩이를 갑자기 손으로 움켜쥐었다.이로써 피고인은 피해자를 강제로 추행하였다. (Score: 0.7840)\n",
      "피해자 D(가명)에게 다가가 ‘자기야'라고 말하면서 피해자 왼편에 서서 오른 팔로 피해자의 어깨를 감싸 안아 피해자를 강제로 추행하였다. (Score: 0.7435)\n",
      "술을 마시던 중 자리에서 일어나 피해자에게 다가가 오른손을 피해자 옷 속에 집어넣어 왼쪽 가슴을 4회 만졌다.이로써 피고인은 피해자를 강제로 추행하였다. (Score: 0.7283)\n",
      "갑자기 테이블 바깥쪽에 앉아있던 피해자 C(여, 39세)의 왼쪽 가슴을 3회 만져 피해자를 강제로 추행하였다. (Score: 0.7032)\n",
      "피고인은 종업원인 피해자 C(여, 21세)와 이야기를 하면서 갑자기 손으로 피해자의 가슴을 3회 가량 쳐 피해자를 강제로 추행하였다. (Score: 0.7030)\n"
     ]
    }
   ],
   "source": [
    "corpus = ['갑자기 테이블 바깥쪽에 앉아있던 피해자 C(여, 39세)의 왼쪽 가슴을 3회 만져 피해자를 강제로 추행하였다.',\n",
    "          '주거지에 찾아와 \"같이 살자\"라고 말을 하며 피해자의 상의를 걷어 올려 양손으로 피해자의 양쪽 가슴을 수차례 주무른 후 피해자의 손을 잡아채 피고인의 성기에 가져가 피고인의 성기를 만지게 하고, 이어 피해자의 바지 위에 손을 얹어 피해자의 음부를 만졌다.\\\\n2. 2020. 8. 8.자 범행\\\\n피고인은 2020. 8. 8. 09:00경 제1항의 피해자 주거지에서, 마당에 있다가 집 안으로 들어가는 피해자를 따라 들어가 피해자의 상의 옷 안으로 한 손을 넣어 가슴을 주무르고, 피해자의 바지 속에 손을 넣어 피해자의 음부를 만졌다.\\\\n이로써 피고인은 피해자를 강제로 추행하였다.',\n",
    "          \"피해자 D(가명)에게 다가가 ‘자기야'라고 말하면서 피해자 왼편에 서서 오른 팔로 피해자의 어깨를 감싸 안아 피해자를 강제로 추행하였다.\",\n",
    "          '피고인은 종업원인 피해자 C(여, 21세)와 이야기를 하면서 갑자기 손으로 피해자의 가슴을 3회 가량 쳐 피해자를 강제로 추행하였다.',\n",
    "          \"피해자에게 ‘한번 하자, 안 해주면 안 간다. 아는 사람을 시켜서 장사 못하게 한다.'라는 등의 말을 하면서 성관계를 요구하였으나 피해자가 이를 거절하자 갑자기 피해자의 엉덩이와 가슴을 손으로 수회 움켜잡고, 이를 뿌리치고 일어나는 피해자에게 ‘한번 안아주면 가겠다.'라고 말하여 이에 피해자가 어쩔 수 없이 응하자 그 틈을 타 피해자의 팬티 안으로 손을 집어넣어 피해자의 음부를 수회 움켜쥐는 등 피해자를 강제로 추행하였다.\"\n",
    "          '피고인과 피해자 B(여, 37세)는 학교 선후배 사이로 알고 지내는 관계이다. 식당의 1, 2층을 연결하는 내부 계단 중간 부분에서, 피해자와 마주치자 갑자기 손으로 피해자의 허리를 끌어당겨 안으면서 피해자에게 \"이러면 내가 따먹는다\"라고 말하여 피해자를 강제로 추행하였다.',\n",
    "          '차량 안에서 갑자기 피해자의 머리를 세게 잡아당겨 입술에 키스하였고, 같은 날 23:50경 같은 시에 있는 번지불상의 도로를 진행하는 위 차량 안에서 운전 중인 피해자의 가슴을 만지려고 시도하여 피해자가 피고인의 손을 쳐내면서 \"뭐하는 거냐, 술집 여자도 아닌데?\"라고 항의하는데도 \"가슴이 예쁘다, 하나도 안 꺼졌다\"라고 말하면서 피해자의 블라우스 안으로 손을 집어넣고 가슴을 주물렀다.거부하는데도 \"나랑 만나는 거 생각해 봐, 남편한테 너를 빼앗아 오겠다, 익산에 가서 먹겠다\"라고 말하면서 피해자의 블라우스 안으로 손을 집어 넣고 가슴을 여러 번 주물렀다.하차하려는 피해자를 제지하면서 머리를 잡아당겨 입술에 키스하고, 피해자의 블라우스를 세게 잡아당겨 단추가 뜯어지자 피해자의 가슴을 입으로 빨고, \"모텔에 같이 가자\"고 말하면서 피해자의 바지 후크를 풀어 지퍼를 내리고 손을 집어넣어 피해자의 음부를 만졌다.\\\\n이로써 피고인은 피해자를 추행하였다.',\n",
    "          '피고인의 집에서, 피고인의 부탁으로 기타를 가르쳐 주러 온 피해자가 피고인의 방침대에 걸터앉아 휴대폰 충전을 하고 있는 것을 보고 피해자의 뒤로 다가가, 갑자기 양팔로 피해자의 허리를 껴안으면서 \"나 섹스하고 싶어\"라고 말하고, 이에 피해자가 피고인의 손을 뿌리치자, 양팔을 빼는 과정에서 갑자기 손으로 피해자의 허벅지 부위를 쓸어내리듯이 만지고, 이에 피해자가 피고인을 피하여 자리에서 일어나자, 피해자의 손목을 잡아 피해자를 침대에 다시 앉힌 다음 피해자의 뒤에서 갑자기 양팔로 피해자의 허리를 껴안으면서 피해자에게 \"진짜 한번만 해 주면 안 돼?\"라고 말하고, 계속하여 피고인을 피하여 자리에서 일어나 나가려고 하는 피해자의 팔을 끌어 당겨 피해자가 침대 앞에 있는 피아노 의자에 앉자, 피해자에게 \"너 손 작다.\"라고 말하면서 갑자기 피해자의 손에 깍지를 끼고, 이에 또다시 피해자가 손을 뺐다. 계속하여 피고인은 피해자에게\"나 진짜 못 참겠으니까 한번만 하자\"라고 하면서 갑자기 피해자의 손목을 잡아당겼다.\\\\n이로써 피고인은 피해자를 강제로 추행하였다.',\n",
    "          \"술을 마시던 중 자리에서 일어나 피해자에게 다가가 오른손을 피해자 옷 속에 집어넣어 왼쪽 가슴을 4회 만졌다.이로써 피고인은 피해자를 강제로 추행하였다.\",\n",
    "          '피고인의 옆에서 수영 강습을 받기 위해 물에 엎드린 자세로 떠 있던 피해자의 엉덩이를 갑자기 손으로 움켜쥐었다.이로써 피고인은 피해자를 강제로 추행하였다.']\n",
    "\n",
    "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "query = ['피고인은 엉덩이를 손으로 움켜쥐어 피해자를 강제로 추행하였다.']\n",
    "\n",
    "query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "cos_scores = cos_scores.cpu()\n",
    "\n",
    "top_k = 5\n",
    "\n",
    "top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
    "\n",
    "print(\"\\n\\n======================\\n\\n\")\n",
    "print(\"Query:\", query)\n",
    "print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "for idx in top_results[0:top_k]:\n",
    "  print(corpus[idx].strip(), \"(Score: %.4f)\" % (cos_scores[idx]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
